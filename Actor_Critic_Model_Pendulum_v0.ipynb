{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Actor Critic Model Pendulum v0",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycU-rVm3PwxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "d556b3b6-f841-4c1c-d0e6-256da5f2fb74"
      },
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "from keras.layers.merge import Add, Multiply\n",
        "\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "class ActorCritic():\n",
        "\n",
        "    def __init__(self, env, sess):\n",
        "        self.env = env\n",
        "        self.sess = sess\n",
        "\n",
        "        self.learning_rate = 0.001\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_decay = .995\n",
        "        self.gamma = .95\n",
        "        self.tau = .125\n",
        "        self.memory = deque(maxlen=2000)\n",
        "\n",
        "\n",
        "        # Actor\n",
        "        self.actor_state_input, self.actor_model = self.create_actor()\n",
        "\n",
        "        _, self.target_actor_model = self.create_actor()\n",
        "        \n",
        "        self.actor_critic_grad = tf.Variable(dtype=tf.float32, shape=[1, self.env.action_space.shape[0]])\n",
        "\n",
        "        actor_model_weights = self.actor_model.trainable_weights\n",
        "        self.actor_grads = tf.gradients(self.actor_model.output, actor_model_weights, -self.actor_critic_grad)\n",
        "        grads = zip(self.actor_grads, actor_model_weights)\n",
        "        self.optimize = tf.train.AdamOptimizer(self.learning_rate).apply_gradients(grads)\n",
        "\n",
        "        # Critic\n",
        "        self.critic_state_input, self.critic_action_input, self.critic_model = self.create_critic()\n",
        "        \n",
        "        _, _, self.target_critic_model = self.create_critic()\n",
        "        \n",
        "        self.critic_grads = tf.gradients(self.critic_model.output, self.critic_action_input) \n",
        "        \n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    def create_actor(self):\n",
        "        state_input = Input(shape=self.env.observation_space.shape)\n",
        "        h1 = Dense(24, activation='relu')(state_input)\n",
        "        h2 = Dense(48, activation='relu')(h1)\n",
        "        h3 = Dense(24, activation='relu')(h2)\n",
        "        output = Dense(self.env.action_space.shape[0], activation='relu')(h3)\n",
        "\n",
        "        model = Model(inputs=state_input, outputs=output)\n",
        "        adam = Adam(lr=0.001)\n",
        "        model.compile(loss='mse', optimizer=adam)\n",
        "        \n",
        "        return state_input, model\n",
        "\n",
        "    def create_critic(self):\n",
        "        state_input = Input(shape=self.env.observation_space.shape)\n",
        "        state_h1 = Dense(24, activation='relu')(state_input)\n",
        "        state_h2 = Dense(48)(state_h1)\n",
        "\n",
        "        action_input = Input(shape=self.env.action_space.shape)\n",
        "        action_h1 = Dense(48)(action_input)\n",
        "\n",
        "        merged = Add()([state_h2, action_h1])\n",
        "        merged_h1 = Dense(24, activation='relu')(merged)\n",
        "        output = Dense(1, activation='relu')(merged_h1)\n",
        "\n",
        "        model = Model(inputs=[state_input, action_input], outputs=output)\n",
        "        adam = Adam(lr=0.001)\n",
        "        model.compile(loss='mse', optimizer=adam)\n",
        "\n",
        "        return state_input, action_input, model\n",
        "\n",
        "    def remember(self, cur_state, action, reward, new_state, done):\n",
        "        self.memory.append([cur_state, action, reward, new_state, done])\n",
        "\n",
        "\n",
        "    def train_actor(self, samples):\n",
        "        for sample in samples:\n",
        "            cur_state, action, reward, new_state, _ = sample\n",
        "            predicted_action = self.actor_model.predict(cur_state)\n",
        "            grads = self.sess.run(self.critic_grads, feed_dict={\n",
        "                self.critic_state_input: cur_state,\n",
        "                self.critic_action_input: predicted_action\n",
        "            })\n",
        "\n",
        "            self.sess.run(self.optimize, feed_dict={\n",
        "                self.actor_state_input: cur_state,\n",
        "                self.actor_critic_grad: grads\n",
        "            })\n",
        "            \n",
        "    def train_critic(self, samples):\n",
        "        for sample in samples:\n",
        "            cur_state, action, reward, new_state, done = sample\n",
        "            if not done:\n",
        "                target_action = self.target_actor_model.predict(new_state)\n",
        "                future_reward = self.target_critic_model.predict([new_state, target_action])[0][0]\n",
        "                reward += self.gamma * future_reward\n",
        "\n",
        "            self.critic_model.fit([cur_state, action], reward, verbose=0)\n",
        "\n",
        "    def train(self):\n",
        "        batch_size = 32\n",
        "        if len(self.memory) < 32:\n",
        "            return\n",
        "        \n",
        "        rewards = []\n",
        "        samples = random.sample(self.memory, batch_size)\n",
        "        self.train_actor(samples)\n",
        "        self.train_critic(samples)\n",
        "\n",
        "    def _update_actor_target(self):\n",
        "        actor_model_weights  = self.actor_model.get_weights()\n",
        "        actor_target_weights = self.target_critic_model.get_weights()\n",
        "    \n",
        "        for i in range(len(actor_target_weights)):\n",
        "            actor_target_weights[i] = actor_model_weights[i]\n",
        "        self.target_critic_model.set_weights(actor_target_weights)\n",
        "\n",
        "    def _update_critic_target(self):\n",
        "        critic_model_weights  = self.critic_model.get_weights()\n",
        "        critic_target_weights = self.critic_target_model.get_weights()\n",
        "        \n",
        "        for i in range(len(critic_target_weights)):\n",
        "            critic_target_weights[i] = critic_model_weights[i]\n",
        "        self.critic_target_model.set_weights(critic_target_weights)\t\t\n",
        "\n",
        "    def update_target(self):\n",
        "        self._update_actor_target()\n",
        "        self._update_critic_target()\n",
        "\n",
        "    def act(self, cur_state):\n",
        "        self.epsilon += self.epsilon_decay\n",
        "        if np.random.random() < self.epsilon:\n",
        "            return self.env.action_space.sample()\n",
        "        return self.actor_model.predict(cur_state)\n",
        "\n",
        "def main():\n",
        "    sess = tf.compat.v1.Session()\n",
        "    # K.set_session(sess)\n",
        "    env = gym.make('Pendulum-v0')\n",
        "    actor_critic = ActorCritic(env, sess)\n",
        "\n",
        "    num_trials = 10000\n",
        "    trial_len = 500\n",
        "\n",
        "    cur_state = env.reset()\n",
        "    action = env.action_space.sample()\n",
        "\n",
        "    while True:\n",
        "        env.render()\n",
        "        cur_state = cur_state.reshape((1, env.observation_space.shape[0]))\n",
        "        print (cur_state)\n",
        "        action = actor_critic.act(cur_state)\n",
        "        action = action.reshape((1, env.action_space.shape[0]))\n",
        "\n",
        "        new_state, reward, done, _ = env.step(action)\n",
        "        new_state = new_state.reshape((1, env.observation_space.shape[0]))\n",
        "\n",
        "        actor_critic.remember(cur_state, action, reward, new_state, done)\n",
        "        actor_critic.train()\n",
        "\n",
        "        cur_state = new_state\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1b4ce8ea959a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-1b4ce8ea959a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# K.set_session(sess)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pendulum-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mactor_critic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActorCritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mnum_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-1b4ce8ea959a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, sess)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_actor_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_critic_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mactor_model_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v2_call\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kws)\u001b[0m\n\u001b[1;32m    234\u001b[0m                         shape=None):\n\u001b[1;32m    235\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator_v2\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2645\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m       shape=shape)\n\u001b[0m\u001b[1;32m   2648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1432\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m   def _init_from_args(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1510\u001b[0m             synchronization, aggregation, trainable, name))\n\u001b[1;32m   1511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"initial_value must be specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1513\u001b[0m     \u001b[0minit_from_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: initial_value must be specified."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sijzqH7HP16K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o4C9z-OQRFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}