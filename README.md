## STUDY LOGS 

- Problem Formation in RL, use of K-arm bandit Problem
- Introduction of Key Terminologies **state, action, environment, policy, value, reward, discount, expolration, exploitation, Probability 	  Distributions** 
- State Value Approximation, Action Value Approximation, Bellman Equation, Tansition Probability (Pss')
- Bellman Expectation Equation, Bellman Optimality Equations
- Markov Property, Markov Process, Markov Reward Process, Markov Decision Process
- Computation Complexity, Dyanamic Programming, Monte Carlo Simulation, Temporal Difference learning 
- PREDICTION AND CONTROL
- Dyanamic Programming **Policy Evaluation, Policy Iteration**
- Deterministic Policy, E-Greedy Policy
- Value Iteration **Optimality**
- Incremental mean, Episodes, First Visit Monte Carlo Simulation, Sampling, Model Free Predictions **High vairance + Zero Bias**
- Bootstraping, Incomplete episodes, Temporal Difference Learning, Going to Office, Sutton Book **Low Variance + Some Bias**
- Off Policy learning, On Policy Learning 
- Model Free Control, SARSA-0, SARSA max, Exploited SARSA **Q learning** 
- Value Function approximation, Neural networks, Moving Target Concept, Deep Q-Learning **Function Approximators + Optimisations**
- Replay buffer**Experience Replay**
- Policy Gradients

